{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a57e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless\n",
    "!pip install torchvision --index-url https://download.pytorch.org/whl/cpu\n",
    "\n",
    "## required for Yolov7\n",
    "!pip install pyyaml\n",
    "!pip install scipy\n",
    "!pip install \"numpy>=1.18.5,<1.24.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d30cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('./yolov7')\n",
    "import sys\n",
    "sys.path.append('./')\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from numpy import random\n",
    "\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "\n",
    "from utils.general import  non_max_suppression, scale_coords\n",
    "from utils.plots import plot_one_box\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import kneronnxopt\n",
    "import onnx\n",
    "\n",
    "import ktc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61ee52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_PATH = \"./yolov7/yolov7-tiny.onnx\" \n",
    "m = onnx.load(ONNX_PATH)\n",
    "md_opt = ktc.onnx_optimizer.onnx2onnx_flow(m)\n",
    "onnx.save(md_opt,'/data1/kneopi_yolov7-tiny_opt.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "km = ktc.ModelConfig(11111, \"0001\", \"730\", onnx_model=md_opt)\n",
    "\n",
    "# npu(only) performance simulation\n",
    "eval_result = km.evaluate()\n",
    "print(\"\\nNpu performance evaluation result:\\n\" + str(eval_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6851162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.chdir('./yolov7')\n",
    "import sys\n",
    "sys.path.append('./')\n",
    "from utils.general import  non_max_suppression, scale_coords\n",
    "from utils.plots import plot_one_box\n",
    "\n",
    "def preprocess(img, model_input_w, model_input_h):\n",
    "\n",
    "    img = cv2.resize(img, (model_input_w, model_input_h)).astype(np.float32)\n",
    "    img = np.transpose(img, (2,0,1))\n",
    "    img /= 255.0\n",
    "    img = np.expand_dims(img, axis=[0])\n",
    "\n",
    "    return img\n",
    "\n",
    "def post_process(model_inf_data):\n",
    "    pred = []\n",
    "    for o_n in model_inf_data:\n",
    "        pred.append(torch.from_numpy(o_n))\n",
    "\n",
    "    anchors = []\n",
    "    anchors.append([12,16, 19,36, 40,28])  \n",
    "    anchors.append([36,75, 76,55, 72,146])  \n",
    "    anchors.append([142,110, 192,243, 459,401])  \n",
    "\n",
    "    nl = len(anchors)  # number of detection layers\n",
    "    grid = [torch.zeros(1)] * nl  # init grid\n",
    "\n",
    "    a = torch.tensor(anchors).float().view(nl, -1, 2)\n",
    "    anchor_grid = a.clone().view(nl, 1, -1, 1, 1, 2)\n",
    "    stride = torch.tensor([8. , 16. , 32.])  \n",
    "\n",
    "    for idx, every_stride in enumerate(np.array(stride.view(-1, 1, 1)).squeeze()):\n",
    "        anchors[idx] /= every_stride\n",
    "\n",
    "    scaled_res = []\n",
    "\n",
    "    for i in range(len(anchors)):\n",
    "        if grid[i].shape[2:4] != pred[i].shape[2:4]:\n",
    "            bs, _, ny, nx, _ = pred[i].shape\n",
    "            grid[i] = _make_grid(nx, ny).to('cpu')\n",
    "\n",
    "        y = sigmoid(pred[i])\n",
    "\n",
    "        y[..., 0:2] = (y[..., 0:2] * 2. - 0.5 + grid[i]) * stride[i]  # xy\n",
    "        y[..., 2:4] = (y[..., 2:4] * 2) ** 2 * anchor_grid[i]  # wh\n",
    "\n",
    "        scaled_res.append(y.reshape([bs,-1,85]))\n",
    "\n",
    "    concat_pred = torch.concat(scaled_res,dim=1)\n",
    "\n",
    "    # Apply NMS\n",
    "    batch_det = non_max_suppression(concat_pred, conf_thres=0.25, iou_thres=0.45)\n",
    "    return batch_det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0846ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## onnx model check using onnxruntime\n",
    "im0 = cv2.imread('/data1/yolov7/inference/images/bus.jpg')\n",
    "\n",
    "# resize and normalize input data\n",
    "img = preprocess(im0, model_input_w = 640, model_input_h = 640)\n",
    "\n",
    "# onnx inference using onnxruntime\n",
    "OPTIMIZED_ONNX_PATH = \"/data1/kneopi_yolov7-tiny_opt.onnx\" \n",
    "ort_session = ort.InferenceSession(OPTIMIZED_ONNX_PATH)\n",
    "model_pred = ort_session.run(None, {'images': img})\n",
    "\n",
    "# onnx output data processing\n",
    "batch_det = post_process(model_pred)\n",
    "det = batch_det[0] #only one image\n",
    "\n",
    "# visualize segmentation result to img\n",
    "if len(det):\n",
    "    cls_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in cls_names]\n",
    "\n",
    "    # Rescale boxes from img_size to im0 size\n",
    "    det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "    # Write results\n",
    "    for *xyxy, conf, cls in reversed(det):\n",
    "        label = f'{cls_names[int(cls)]} {conf:.2f}'\n",
    "        plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=1)\n",
    "\n",
    "    # Save results (image with detections)\n",
    "    save_path = os.path.abspath(\"/data1/kneopi_onnxruntime_inf.jpg\")\n",
    "    cv2.imwrite(save_path, im0)\n",
    "\n",
    "    print(\"save result to \" + save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d01d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## onnx model check using ktc.inference\n",
    "im0 = cv2.imread('/data1/yolov7/inference/images/bus.jpg')\n",
    "\n",
    "# resize and normalize input data\n",
    "img = preprocess(im0, model_input_w = 640, model_input_h = 640)\n",
    "\n",
    "# onnx inference using ktc.inference\n",
    "OPTIMIZED_ONNX_PATH = \"/data1/kneopi_yolov7-tiny_opt.onnx\" \n",
    "model_pred = ktc.kneron_inference([img], input_names=['images'], onnx_file=OPTIMIZED_ONNX_PATH, platform=730)\n",
    "\n",
    "# onnx output data processing\n",
    "batch_det = post_process(model_pred)\n",
    "det = batch_det[0] #only one image\n",
    "\n",
    "# visualize detection result to img\n",
    "if len(det):\n",
    "    cls_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in cls_names]\n",
    "\n",
    "    # Rescale boxes from img_size to im0 size\n",
    "    det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "    # Write results\n",
    "    for *xyxy, conf, cls in reversed(det):\n",
    "        label = f'{cls_names[int(cls)]} {conf:.2f}'\n",
    "        plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=1)\n",
    "\n",
    "    # Save results (image with detections)\n",
    "    save_path = os.path.abspath(\"/data1/kneopi_tc_onnx_inf.jpg\")\n",
    "    cv2.imwrite(save_path, im0)\n",
    "\n",
    "    print(\"save result to \" + save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e022de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and normalize all image data from folder\n",
    "q_imgs_path = \"/data1/test_image10/\"\n",
    "images_list = glob.glob(q_imgs_path+'*'+ '.jpg')\n",
    "\n",
    "normalized_img_list = []\n",
    "for img_path in images_list:\n",
    "\n",
    "    img_name = img_path.split(\"/\")[-1]\n",
    "    img = cv2.imread(os.path.join(q_imgs_path, img_name), cv2.IMREAD_COLOR)\n",
    "\n",
    "    model_input_w, model_input_h = 640, 640\n",
    "    img = preprocess(img, model_input_w, model_input_h)\n",
    "\n",
    "    normalized_img_list.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d178b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix point analysis\n",
    "bie_model_path = km.analysis({\"images\": normalized_img_list})\n",
    "print(\"\\nFix point analysis done. Save bie model to '\" + str(bie_model_path) + \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a91db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bie model check using ktc.inference\n",
    "im0 = cv2.imread('/data1/yolov7/inference/images/bus.jpg')\n",
    "\n",
    "# resize and normalize input data\n",
    "img = preprocess(im0, model_input_w = 640, model_input_h = 640)\n",
    "\n",
    "# bie inference using ktc.inference\n",
    "BIE_PATH = \"/data1/kneron_flow/input.kdp730.scaled.release.bie\" \n",
    "model_pred = ktc.kneron_inference([img], input_names=['images'], bie_file=BIE_PATH, platform=730)\n",
    "\n",
    "\n",
    "# bie output data processing\n",
    "batch_det = post_process(model_pred)\n",
    "det = batch_det[0] #only one image\n",
    "\n",
    "# visualize segmentation result to img\n",
    "if len(det):\n",
    "    cls_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in cls_names]\n",
    "\n",
    "    # Rescale boxes from img_size to im0 size\n",
    "    det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "    # Write results\n",
    "    for *xyxy, conf, cls in reversed(det):\n",
    "        label = f'{cls_names[int(cls)]} {conf:.2f}'\n",
    "        plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=1)\n",
    "\n",
    "    # Save results (image with detections)\n",
    "    save_path = os.path.abspath(\"/data1/kneopi_tc_bie_inf.png\")\n",
    "    cv2.imwrite(save_path, im0)\n",
    "\n",
    "    print(\"save result to \" + save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e675d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "nef_model_path = ktc.compile([km])\n",
    "print(\"\\nCompile done. Save Nef file to '\" + str(nef_model_path) + \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb9cc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "## nef model check using ktc.inference\n",
    "im0 = cv2.imread('/data1/yolov7/inference/images/bus.jpg')\n",
    "\n",
    "# resize and normalize input data\n",
    "img = preprocess(im0, model_input_w = 640, model_input_h = 640)\n",
    "\n",
    "# nef inference using ktc.inference\n",
    "NEF_PATH = \"/data1/kneron_flow/models_730.nef\" \n",
    "model_pred = ktc.kneron_inference([img], input_names=['images'], nef_file=NEF_PATH, platform=730)\n",
    "\n",
    "\n",
    "# nef output data processing\n",
    "batch_det = post_process(model_pred)\n",
    "det = batch_det[0] #only one image\n",
    "\n",
    "# visualize segmentation result to img\n",
    "if len(det):\n",
    "    cls_names = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "    colors = [[random.randint(0, 255) for _ in range(3)] for _ in cls_names]\n",
    "\n",
    "    # Rescale boxes from img_size to im0 size\n",
    "    det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "    # Write results\n",
    "    for *xyxy, conf, cls in reversed(det):\n",
    "        label = f'{cls_names[int(cls)]} {conf:.2f}'\n",
    "        plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=1)\n",
    "\n",
    "    # Save results (image with detections)\n",
    "    save_path = os.path.abspath(\"/data1/kneopi_tc_nef_inf.png\")\n",
    "    cv2.imwrite(save_path, im0)\n",
    "\n",
    "    print(\"save result to \" + save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
